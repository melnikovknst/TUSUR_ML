{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1pH4JDH6fTTKhozhD5ryu_GOcZ-m81U_s","timestamp":1731425419149}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ML vs DL vs DS vs AI"],"metadata":{"id":"Kq-BMIspeHuI"}},{"cell_type":"markdown","source":["**Искусственный интеллект (Artificial Intelligence, AI)** — это широкая область компьютерных наук, направленная на создание систем, способных выполнять задачи, которые обычно требуют человеческого интеллекта. К таким задачам относятся понимание естественного языка, распознавание образов, принятие решений, решение проблем и так далее. По сути, AI стремится создать машины, которые могут «думать» и «учиться», хотя и на уровне, отличающемся от человеческого.\n","\n","AI включает в себя множество различных подходов и методов. На начальном этапе развития AI использовались алгоритмы, построенные на жестких правилах (например, логические системы или системы на основе принятия решений). Однако с развитием компьютерных мощностей и данных, подходы AI стали более сложными и динамичными."],"metadata":{"id":"hu65r4jBqBgW"}},{"cell_type":"markdown","source":["**Машинное обучение (Machine Learning, ML)** — это подмножество искусственного интеллекта, которое фокусируется на разработке алгоритмов, позволяющих системам обучаться на основе данных, а не через явное программирование. В традиционном программировании мы явно пишем правила, по которым работает программа, тогда как в ML модель изучает эти правила самостоятельно, анализируя примеры.\n","\n","Проще говоря, ML — это метод, который позволяет компьютерам обучаться и делать прогнозы на основе данных. Например, система может научиться классифицировать изображения, предсказывать тренды продаж или распознавать речь, если ей предоставить достаточно примеров для обучения."],"metadata":{"id":"xcJsejRcqJxY"}},{"cell_type":"markdown","source":["**Глубокое обучение (Deep Learning, DL)** — это подмножество машинного обучения, основанное на нейронных сетях, состоящих из множества слоев. Слово «глубокое» относится к числу этих слоев, которые могут быть достаточно многочисленными. Глубокие нейронные сети способны автоматизировать процесс выделения признаков и распознавать сложные паттерны в данных.\n","\n","DL стал возможен благодаря значительному росту вычислительных мощностей и доступности больших данных. Например, современные системы глубокого обучения используются для распознавания образов (например, в Google Photos), обработки естественного языка (например, в виртуальных помощниках, таких как Siri или Alexa), и многих других задач.\n","\n","DL отличается от традиционных методов ML тем, что модель может самостоятельно находить иерархии признаков в данных. Например, в задаче распознавания изображений начальные слои нейронной сети могут выделять простые признаки, такие как края и текстуры, в то время как более высокие слои формируют более сложные концепции, такие как формы и объекты."],"metadata":{"id":"ea3itUP8qP2E"}},{"cell_type":"markdown","source":["<img src=\"https://storage.yandexcloud.net/cloud-www-assets/blog-assets/ru/posts/2022/09/machine-learnig-1.png\" width=700></img>\n"],"metadata":{"id":"1PQrnhMxiW_A"}},{"cell_type":"markdown","source":["**Data Science (DS)** — это междисциплинарная область, которая использует методы, процессы, алгоритмы и системы для извлечения знаний и инсайтов из структурированных и неструктурированных данных. По сути, это область, которая объединяет элементы математики, статистики, информатики и специализированных знаний в предметной области для анализа данных и извлечения полезной информации."],"metadata":{"id":"Pv2oRTsFcBQp"}},{"cell_type":"markdown","source":["<img src=\"https://miro.medium.com/v2/resize:fit:1400/0*LeeSR2lsy8SFrQup\" width=900></img>"],"metadata":{"id":"Lgvvcc5tppJx"}},{"cell_type":"markdown","source":["# Типы задач в ML"],"metadata":{"id":"IqgsU6Q2eWn7"}},{"cell_type":"markdown","source":["Предположим, имеется описание какой-то квартиры в Москве, и требуется определить, сколько она реально стоит на рынке.\n","\n","При постановке задачи машинного обучения **нужно в первую очередь разобраться, для чего необходимо сделать предсказание**. То, для чего мы делаем предсказание, называется объектом, в нашем примере объект — это конкретная квартира. То, что мы предсказываем, называется целевой переменной, и в нашем примере это рыночная стоимость объекта — квартиры. Соответственно, по объекту предсказывается ответ.\n","\n","В каждой задаче важно разобраться с объектом и ответом. Например, если мы хотим бороться с оттоком клиентов, то объектом будет конкретный клиент в данный момент времени, а ответом будет факт того, что он уйдет, скажем, в течение месяца. В задаче будет проводиться, собственно, предсказание этой переменной.\n","\n","От вида ответа (хотя и не только от него) зависит тип задачи.\n","В примере про квартиры предсказывается их стоимость — число от 0 до бесконечности. Такие **задачи по предсказанию чисел называются задачами регрессии**. Примеров много: предсказание цен на товар, цен на акции.\n","\n","Бывают **задачи классификации, в которых ответов содержится ограниченное количество**. Например, дается текст какой-то новости, и нужно понять тему текста — политика, спорт, знаменитости, наука. В такой задаче требуется выбрать один конкретный вариант из четырех возможных. Примеров классификации тоже много. Собственно, задача про отток, где предсказывалось, уйдет клиент или не уйдет, — это классификация. Если мы хотим предсказать, сколько сотрудников выводить в отделение в конкретный день, можно выбрать разные варианты, например, три — 5, 10 или 15 сотрудников. Это тоже задача классификации.\n","\n","В нашем примере для некоторых квартир дано их описание, количество и стоимость — это обучающая выборка. По ней компьютер должен построить алгоритм для предсказания стоимости любой квартиры в Москве — **это пример задачи обучения с учителем**.\n","\n","Но бывают и другие направления. Одно из них — **обучение без учителя**. В этих задачах **нет правильных ответов**. Компьютеру даются некоторые объекты, скажем, выборка всех клиентов Сбера, и нужно какие-то выводы сделать по этой выборке. Например, понять, какие есть типы клиентов, найти самых характерных клиентов или аномальных клиентов. Примеров решения нет, есть просто данные.\n","\n"],"metadata":{"id":"BRkpeHKn6MGE"}},{"cell_type":"markdown","source":["<img src=\"https://storage.yandexcloud.net/cloud-www-assets/blog-assets/ru/posts/2022/09/machine-learning-types-1.png\" width=900></img>\n","\n"],"metadata":{"id":"Add234GT5tf6"}},{"cell_type":"markdown","source":["## Виды ML"],"metadata":{"id":"AakG4Xa27Olt"}},{"cell_type":"markdown","source":["Мы рассмотрели типы задач в ML. Однако также выделяют виды задач, где классификация идёт на основе сложности используемых моделей.\n","\n","**Классическое машинное обучение** — это набор алгоритмов и методов, которые были разработаны и использовались до эпохи глубокого обучения и искусственных нейронных сетей. Эти методы основываются на математических моделях и статистических принципах для анализа данных, предсказания и нахождения зависимостей. В отличие от глубокого обучения, где акцент делается на автоматическое извлечение признаков из данных с помощью нейронных сетей, классическое машинное обучение требует явного выбора признаков (feature engineering) и чаще используется при работе с относительно небольшими наборами данных.\n","\n","Однако **деление на «обучение с учителем» и «обучение без учителя» применяется не только для алгоритмов классического ML**. Эти подходы также успешно используются как в ансамблях, так и в глубоких сетях.\n","\n","**Ансамблевые методы** объединяют несколько моделей для получения более точных и стабильных предсказаний, что улучшает качество модели за счет уменьшения переобучения и повышения общей производительности. Переобучение — это эффект, когда модель слишком хорошо \"запоминает\" обучающие данные и из-за этого не может сделать адекватные прогнозы на новых данных.\n","\n","**Модели глубокого обучения** работают по прицнипу «чёрного ящика» из-за их сложности и непрозрачности в понимании того, как именно они принимают решения. В отличие от моделей, где можно напрямую понять влияние каждого входного признака на результат (например, в линейной регрессии коэффициенты показывают влияние каждого признака), в нейронных сетях такой прямой интерпретации нет. Даже если известны все веса и смещения, сложно проследить, как конкретный входной сигнал прошел через сеть и повлиял на результат.\n","\n"],"metadata":{"id":"Zmo_esYDOGbM"}},{"cell_type":"markdown","source":["\n","<img src=\"https://s0.rbk.ru/v6_top_pics/resized/800xH/media/img/0/69/756237500508690.jpeg\" width=500></img>"],"metadata":{"id":"yqoP5Rkd7SAz"}},{"cell_type":"markdown","source":["Бывают и более сложные направления, как **обучение с подкреплением — Reinforcement Learning**. Здесь модель или алгоритм выступает агентом, который действует в среде (например, робот в окружающем мире или модель персонажа в игровом мире) и сразу получает обратную связь. Можно представить, что компьютер сидит за рулем автомобиля и управляет им: он может нажать на газ, нажать на тормоз или повернуть руль на столько-то градусов влево или вправо. Вначале алгоритм не знает ничего, но после каждого действия он получает обратную связь. Например, если он едет хорошо, с нужной скоростью, ничего не нарушая, получает награду. Если он проехал на красный или «под кирпич», получает отрицательную награду, то есть наказание. Получая награды, компьютер должен постепенно учиться работать с нашей средой и с нашим миром. Сейчас много открытых вопросов в этой области, но она очень перспективная, потому что имитирует процесс обучения человека."],"metadata":{"id":"9hfhY6-pciGi"}},{"cell_type":"markdown","source":["# Жизненный цикл ML-проекта"],"metadata":{"id":"SUXC8BwReZjm"}},{"cell_type":"markdown","source":["## Задачи на каждом этапе ЖЦ"],"metadata":{"id":"_JvkWAVhpkaC"}},{"cell_type":"markdown","source":["**Жизненный цикл ML-проекта** — это процесс, который охватывает все этапы разработки, внедрения и поддержки модели машинного обучения. Этот цикл включает в себя последовательность шагов, начиная от постановки задачи и заканчивая мониторингом и обновлением модели. Давайте подробно рассмотрим каждый из этапов этого жизненного цикла.\n","\n","**1. Постановка задачи и сбор требований**\n","\n","На этом этапе важно чётко определить цель проекта и его бизнес-задачи. Нужно понять, какие конкретные проблемы вы пытаетесь решить с помощью машинного обучения.\n","\n","- Определение целей и показателей успеха\n","- Согласование с заинтересованными сторонами (бизнес-пользователи, менеджеры, технические специалисты)\n","- Сбор требований и ограничений (временные рамки, доступные ресурсы, ограничения по данным)\n","- Определение, где будет работать модель (облако, локальные серверы, мобильные устройства).\n","\n","**2. Сбор и подготовка данных**\n","\n","Данные — это основа любого ML-проекта. На этом этапе осуществляется сбор, очистка и подготовка данных для последующего обучения модели.\n","\n","\n","- Получение данных из различных источников (базы данных, API, файлы, интернет).\n","- Очистка данных: удаление дубликатов, обработка пропущенных значений, исправление ошибок.\n","- Анализ данных: исследование структуры данных, их распределения, взаимосвязей между признаками.\n","- Препроцессинг данных: нормализация, кодирование категориальных признаков, разделение на тренировочный и тестовый наборы.\n","\n","**3. Разработка модели**\n","\n","На этом этапе начинается непосредственное проектирование и обучение моделей машинного обучения.\n","\n","- Определение, какие алгоритмы могут подойти для решения задачи (линейные модели, деревья решений, нейронные сети и т.д.).\n","- Обучение моделей на тренировочных данных, настройка гиперпараметров.\n","- Валидация модели для оценки работы с помощью выбранных метрик.\n","- Повтор всей итерации до удовлетровательных результатов.\n","\n","**4. Тестирование модели**\n","\n","На этом этапе проверяется, насколько хорошо модель работает на данных, которые она не видела во время обучения — это важный шаг для избежания переобучения.\n","\n","- Оценка модели на тестовом наборе данных, который не использовался при обучении.\n","- Анализ результатов, проверка модели на наличие ошибок и их анализ, например, путём построения матрицы ошибок.\n","- Проведение A/B тестирования, проверка на данных, полученных в разные временные периоды.\n","\n","**5. Внедрение модели (Deployment)**\n","\n","После успешной разработки и тестирования модель нужно внедрить в эксплуатационную среду, чтобы она начала решать реальную задачу.\n","\n","- Адаптация модели под выбранную среду. Возможно, на предыдущих этапах модель нужно оптимизировать для работы на CPU или микроконтроллеры.\n","- Подключение модели к рабочим системам, создание API, настройка процессов обработки данных в реальном времени.\n","- Создание документации по использованию модели, описание ограничений и особенностей.\n","\n","**6. Мониторинг и поддержка**\n","\n","После внедрения важно следить за тем, как модель работает в реальных условиях, и своевременно вносить изменения при необходимости.\n","\n","- Мониторинг производительности: регулярная проверка работы модели, анализ метрик, контроль точности, производительности, стабильности.\n","- Периодическое повторное обучение модели на новых данных, адаптация к изменяющимся условиям (например, изменение трендов в данных).\n","- Исправление багов, обновление инфраструктуры, настройка автоматического мониторинга и оповещений."],"metadata":{"id":"3Fmdmmk6CZA7"}},{"cell_type":"markdown","source":["<figure>\n","<img src='https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2021/02/22/2-ML-Lifecycle.jpg' alt='' height='400px'>\n","<figcaption>Жизненный цикл ML-модели</figcaption>\n","</figure>"],"metadata":{"id":"hzD7hsJyAPYV"}},{"cell_type":"markdown","source":["## A/B-тестирование"],"metadata":{"id":"qARkcvGRh70M"}},{"cell_type":"markdown","source":["**A/B-тестирование** — это метод экспериментов, который используется для сравнения двух (или более) вариантов какого-либо элемента, чтобы понять, какой из них работает лучше с точки зрения достижения определённой цели. Этот подход особенно популярен в маркетинге, веб-разработке и продуктовых исследованиях, поскольку позволяет на основе данных принимать решения о том, какой вариант дизайна, текста, функции или действия эффективнее.\n","\n","**Основная идея A/B-тестирования** заключается в том, чтобы разделить аудиторию на две (или несколько) группы и показать каждой из них различные версии тестируемого элемента. Например, если компания хочет выяснить, какой заголовок лучше привлекает внимание пользователей на сайте, то одной группе пользователей показывается версия A (оригинальный заголовок), а другой группе — версия B (новый вариант заголовка). После этого измеряется, как каждая версия повлияла на ключевые метрики (например, клики, покупки, регистрации).\n","\n","A/B-тестирование может использоваться на нескольких уровнях, например, для оценки эффективности моделей или для улучшения взаимодействия с пользователями на основе предсказательных алгоритмов. Например, компания может использовать A/B-тестирование, чтобы сравнить эффективность двух алгоритмов рекомендации (например, одна модель использует бейзлайн-алгоритм, а другая — модель на основе глубокого обучения). Один набор пользователей будет взаимодействовать с первой моделью, другой — со второй, а затем сравниваются результаты (например, конверсии или вовлечённость)."],"metadata":{"id":"OXEdYQN5PXrj"}},{"cell_type":"markdown","source":["## Стадии проекта"],"metadata":{"id":"Gk4AGccKpfQ7"}},{"cell_type":"markdown","source":["> **Baseline** (Базовая линия)\n","\n","**Baseline** — это начальная модель, которая служит отправной точкой для сравнения производительности более сложных моделей. На этом этапе создаётся простейшая модель, которая позволяет оценить, насколько сложные модели могут улучшить результаты.\n","\n","- Оценка исходного уровня: Определение начального уровня производительности, который устанавливается простой моделью или даже базовыми методами, такими как случайное угадывание или простая статистика.\n","- Установление стандартов: Определение минимального уровня производительности, который необходимо превзойти, чтобы модель считалась успешной."],"metadata":{"id":"tac8EzhPLma5"}},{"cell_type":"markdown","source":["> **MVP** (Minimum Viable Product)\n","\n","**MVP** — это минимально жизнеспособный продукт, который включает в себя основной функционал модели, достаточный для решения задачи и получения первой ценности. Это более сложная и усовершенствованная версия по сравнению с базовой моделью.\n","\n","- Создание модели, которая решает проблему и демонстрирует её ценность, даже если не все функции идеально отлажены.\n","- Запуск модели в ограниченном масштабе, чтобы получить отзывы от пользователей и заинтересованных сторон, а также понять, как её можно улучшить.\n","- Проверка предположений о производительности модели и её способности решать поставленную задачу."],"metadata":{"id":"t7Pl88jOLoTI"}},{"cell_type":"markdown","source":["\n","> **Production** (Prod)\n","\n","**Production** — это стадия, на которой модель и сервис вокруг этой модели готовы для полного внедрения и использования в реальных условиях. Она должна быть стабильной, масштабируемой и готовой к работе в производственной среде.\n","\n","- Внедрение модели в реальную эксплуатационную среду, чтобы она могла обрабатывать реальные данные и предоставлять результаты.\n","- Убедиться, что модель работает стабильно и эффективно, обеспечивая высокую производительность и минимизируя ошибки.\n","- Постоянный мониторинг модели, анализ её производительности в реальных условиях, а также регулярное обновление и улучшение модели на основе новых данных и изменений в требованиях.\n"],"metadata":{"id":"LesZ4nzSGPdh"}},{"cell_type":"markdown","source":["# Роли в ML-проектах"],"metadata":{"id":"UBvswq8yeSaa"}},{"cell_type":"markdown","source":["## Аналитик данных"],"metadata":{"id":"Sdb6eVDswt4O"}},{"cell_type":"markdown","source":["**Аналитик данных** специализируется в первую очередь на методах статистического анализа и использует инструменты BI для интерпретации данных. Они играют ключевую роль в понимании текущего состояния бизнеса и принятии обоснованных решений на основе данных. Основная задача любого аналитика данных — получить из данных пользу для бизнеса, продукта или людей.\n","\n","Инструменты, которые аналитик часто использует, включают Excel, SQL, BI-системы, такие как Tableau или Power BI, и иногда языки программирования, такие как Python или R для базовой автоматизации и анализа. Его работа носит более прикладной характер и направлена на понимание текущих процессов или поддержку принятия решений. Часто аналитики данных **взаимодействуют с бизнес-командами**, объясняя им результаты своих исследований и помогая им формировать стратегию."],"metadata":{"id":"3u4vgac5bcGJ"}},{"cell_type":"markdown","source":["<figure>\n","<img src='https://sun9-64.userapi.com/impg/AkPvEeotK4fwcvVyMuVuX1R1G0yGUnmU245rzA/mMZoA9NShCk.jpg?size=1000x1000&quality=96&sign=7a56384d0961da5e073c2513af90023c&type=album' alt='' height='400px'>\n","<figcaption>Data Scientist vs Data Analyst</figcaption>\n","</figure>\n"],"metadata":{"id":"Flk6OYaLuocW"}},{"cell_type":"markdown","source":["## Data Scientist"],"metadata":{"id":"7zt7aJYowZo_"}},{"cell_type":"markdown","source":["**Специалист по обработке данных (Data Scientist)** появился первым и отвечал за обширный набор функционала, но по прошествию времени набор обязанностей сократился, поскольку другие роли взяли часть функционала на себя. Датасаентист обрабатывает массивы данных, находит в них новые связи и закономерности, используя алгоритмы машинного обучения, и строит модели. В нашем понимании, специалист по обработке данных больше не отвечает за автоматические сбор и предобработку данных, это легло на плечи инженера данных, а за интерпретацию результатов и общение с заинтересованными лицами отвечают аналитик данных и BI-аналитик.\n","При этом возросла значимость данной роли в части анализа данных, моделирования и прогнозирования, поскольку требуются большие познания в области программирования и машинного обучения. Анализ данных — это часть работы датасаентиста. Но результат его труда — это модель, код, написанный на основе анализа.\n"],"metadata":{"id":"NucSYjmV1Em5"}},{"cell_type":"markdown","source":["<figure>\n","<img src='https://yastatic.net/s3/education-portal/media/237_1_125a3f92e4_e01e7993a1.png' alt='' height='400px'>\n","<figcaption>Data Scientist: знания и навыки</figcaption>\n","</figure>\n"],"metadata":{"id":"CbKrxaHvwgAN"}},{"cell_type":"markdown","source":["## ML-инженер"],"metadata":{"id":"gnGhwBw0wXNx"}},{"cell_type":"markdown","source":["ML-инженер — специалист, который разрабатывает, внедряет и поддерживает системы машинного обучения. В области Data Science их главная задача усиливать и поддерживать специалистов по обработке данных и аналитиков данных\n","\n","Обязанности:\n","- Разработка и обучение моделей, куда входит выбор алгоритмов, обучение и оценка моделей\n","- Развертывание моделей, интеграция моделей, контейнеризация и оркестрация\n","- Мониторинг и поддержка моделей\n","- Оптимизация и масштабирование инструментов\n","- Внедрение инноваций - поиск и анализ новых технологий, а также внедрение лучших из них в процесс разрабоки\n"],"metadata":{"id":"gokL_aDvyYcD"}},{"cell_type":"markdown","source":["## Data-инженер"],"metadata":{"id":"oV1RVLijx3P2"}},{"cell_type":"markdown","source":["Data-инженеры занимаются проектированием, строительством и поддержанием инфраструктуры для сбора, хранения и обработки данных. Они создают надежные и масштабируемые архитектуры, обеспечивающие непрерывный поток данных для аналитических и ML-проектов. Основные обязанности включают:\n","\n","- Создание ETL-процессов: Разработка процессов для извлечения, трансформации и загрузки данных (Extract, Transform, Load).\n","- Управление базами данных: Проектирование и оптимизация баз данных, работа с большими объемами данных (Data Lakes, Data Warehouses).\n","- Интеграция данных: Обеспечение обмена данными между различными системами и платформами, объединение данных из различных источников для создания единого, целостного представления данных, а также разработка интерфейсов  для доступа к данным другими системами и приложениями.\n","\n","- Обеспечение качества данных: Контроль и улучшение качества данных, настройка систем мониторинга данных.\n","- Автоматизация процессов: Автоматизация задач по обработке данных для повышения эффективности работы."],"metadata":{"id":"-GXZQOaYawKv"}},{"cell_type":"markdown","source":["\n","<figure>\n","<img src='https://habrastorage.org/webt/_o/jd/le/_ojdlejvhdvnakvt6xrxl2k0w5y.png' alt='' width='700px'>\n","<figcaption>Data Engineer: знания и навыки</figcaption>\n","</figure>"],"metadata":{"id":"1VgCTZdW9OB0"}},{"cell_type":"markdown","source":["## MLOps"],"metadata":{"id":"fO7Cw-JAweBE"}},{"cell_type":"markdown","source":["MLOps — это специализированная роль, объединяющая навыки DevOps и машинного обучения. MLOps-инженеры обеспечивают непрерывную интеграцию и доставку моделей, минимизируя разрыв между разработкой моделей и их эксплуатацией в производственной среде. Основные обязанности MLOps-инженера включают:\n","\n","- Разработку автоматизированных CI/CD пайплайнов для развертывания и обновления моделей машинного обучения.\n","- Контроль версий данных и моделей, обеспечение воспроизводимости результатов.\n","- Настройку мониторинга работы моделей, сбор логов и метрик для анализа производительности.\n","- Поддержание инфраструктуры для работы моделей, включая контейнеризацию, оркестрацию и облачные решения.\n","- Работу с вопросами безопасности, конфиденциальности данных и соблюдения стандартов.\n"],"metadata":{"id":"XZvHPMRMa_Bz"}},{"cell_type":"markdown","source":["# ML в бизнесе"],"metadata":{"id":"YEUMT6cZeDvY"}},{"cell_type":"markdown","source":["## Бум развития ML и DL"],"metadata":{"id":"WwqKXGH7uWqI"}},{"cell_type":"markdown","source":["Бум развития машинного и глубокого обучения, особенно в последние десятилетия, связан с несколькими ключевыми факторами: увеличением объёмов данных, улучшением вычислительных мощностей, развитием алгоритмов и архитектур моделей, а также внедрением этих технологий в различные индустрии. Рассмотрим подробно, как и почему этот бум произошёл.\n","\n","> **Объёмы данных**\n","\n","Прежде всего, давайте обратим внимание на данные — основу любого машинного обучения. В последние годы мы наблюдаем **настоящий взрыв объёмов данных**, и это, безусловно, является одним из ключевых факторов, способствующих развитию машинного обучения. **Источниками данных становятся буквально всё**: интернет, социальные сети, мобильные устройства, и, конечно, интернет вещей (IoT). Эти устройства и системы генерируют огромные массивы информации, которая раньше была просто недоступна. Сегодня же мы имеем возможность анализировать эти данные и извлекать из них ценные инсайты, что и делает машинное обучение столь мощным инструментом.\n","\n","> **Производительность железа**\n","\n","Однако большие данные сами по себе мало что значат без соответствующих вычислительных мощностей. Мы видим, как **растёт производительность процессоров и, особенно, графических процессоров (GPU)**. Эти вычислительные мощности сделали возможным обучение глубоких нейронных сетей, о которых мы даже не могли мечтать десять лет назад. Дополнительно, облачные вычисления предоставляют нам неограниченные ресурсы на платформе таких гигантов, как AWS, Google Cloud и Microsoft Azure. Кроме того, специализированные процессоры, такие как Tensor Processing Units (**TPU**) от Google, были разработаны специально для задач машинного обучения.\n","\n","> **Новые архитектуры**\n","\n","Важным аспектом нынешнего бума является совершенствование алгоритмов и архитектур моделей. Глубокие нейронные сети, такие как свёрточные сети для обработки изображений или рекуррентные сети для анализа временных рядов, специальные архитектуры, позволили решать задачи, которые ранее считались практически нерешаемыми.\n","\n","> **Open source и открытые данные**\n","\n","Нельзя не упомянуть и тот факт, что развитие машинного обучения стало возможным благодаря **открытому доступу к знаниям и технологиям**. Сегодня мы имеем доступ к миллионам научных публикаций и открытым программным библиотекам, таким как TensorFlow и PyTorch, что делает передовые технологии доступными буквально каждому, кто готов учиться и экспериментировать. Онлайн-курсы от ведущих университетов позволяют людям по всему миру получать знания, которые раньше были доступны лишь избранным."],"metadata":{"id":"RpG0ibOX7sIH"}},{"cell_type":"markdown","source":["## Сферы"],"metadata":{"id":"KJTDi77ZNMmA"}},{"cell_type":"markdown","source":["Сейчас мы находимся на этапе, когда машинное обучение начинает активно внедряться в различные индустрии. В области компьютерного зрения технологии уже используются для распознавания лиц и даже в автономных автомобилях. Обработка естественного языка позволяет нам создавать чат-ботов, которые успешно имитируют человеческое общение, и автоматизировать перевод текста. В финансовом секторе машинное обучение помогает прогнозировать рыночные тренды и обнаруживать мошенничество, а в здравоохранении — анализировать медицинские снимки и разрабатывать персонализированные методы лечения.\n","\n","Последние годы ознаменовались несколькими знаковыми достижениями, которые продемонстрировали потенциал машинного и глубокого обучения. Победы таких систем, как AlphaGo от DeepMind, над чемпионами мира в игре Го, стали важным этапом в истории искусственного интеллекта. Развитие автопилотов такими компаниями, как Tesla и Waymo, показывает, как глубокое обучение интегрируется в реальные продукты и услуги.\n","\n","В медицинских исследованиях глубокое обучение помогает в раннем распознавании рака, анализе генетических данных и разработке новых методов лечения, что свидетельствует о его огромном потенциале для улучшения качества жизни."],"metadata":{"id":"9b2b8z6O_jwn"}},{"cell_type":"markdown","source":["## BigData"],"metadata":{"id":"d4FwMXCevguP"}},{"cell_type":"markdown","source":["**Big Data** — это термин, обозначающий большие объёмы данных, которые слишком сложны или объёмны для обработки традиционными инструментами и методами управления данными, такими как реляционные базы данных или настольные вычислительные системы. Основные характеристики Big Data описываются концепцией **\"3V\": объём (volume), скорость (velocity) и разнообразие (variety)**.\n","\n","**Объём** данных в Big Data существенно превышает те данные, с которыми можно справиться стандартными системами управления базами данных. Это могут быть терабайты или даже петабайты данных, которые поступают из множества источников: социальных сетей, датчиков, машинного оборудования, веб-логов, транзакционных систем и других источников.\n","\n","**Скорость** в контексте Big Data означает как быстро данные поступают и обрабатываются. В реальном времени данные могут поступать в режиме непрерывного потока, и часто требуется мгновенная их обработка. Например, данные из датчиков интернета вещей (IoT) или финансовые транзакции могут поступать с высокой частотой, и их необходимо обрабатывать немедленно, чтобы извлекать из них полезные данные.\n","\n","**Разнообразие** — это многообразие форматов данных. Данные могут быть структурированными (например, таблицы в базах данных), полуструктурированными (XML, JSON) или неструктурированными (тексты, изображения, видео). Современные подходы к Big Data позволяют работать с данными различных типов одновременно.\n","\n","**Сейчас Big Data часто используется в сочетании с технологиями и подходами машинного обучения, аналитики и прогнозирования**. Данные — это основа для ML, и полученные данные могут анализироваться для создания прогнозных моделей, оптимизации бизнес-процессов или предоставления новых инсайтов.\n","\n","Для обработки Big Data применяются различные инструменты и платформы. Одной из таких платформ является Apache Hadoop — система для распределённого хранения и обработки больших данных, которая использует параллельные вычисления на множестве узлов. Кроме того, широко используются другие инструменты, такие как Apache Spark — платформа для обработки данных в реальном времени, которая отличается высокой скоростью и поддержкой различных языков программирования, таких как Python и Scala. Также используются различные хранилища данных или озера данных, основанные на облачных решениях и предоставляемых крупными компаниями: Amazon, Google, Azure, Snowflake, Cloud.ru, Yandex Cloud, VK Cloud и другие.\n","\n","Big Data активно применяется в самых разных областях. В маркетинге с помощью анализа больших данных компании могут лучше понимать поведение своих клиентов, разрабатывать персонализированные рекламные кампании и прогнозировать спрос. В здравоохранении большие данные используются для анализа медицинских записей, улучшения диагностики заболеваний и поиска новых методов лечения. В промышленности компании могут использовать данные с производственных линий для прогнозирования поломок оборудования и улучшения производственных процессов.\n","\n","> Big Data — это не просто огромные массивы информации, но и целая инфраструктура и набор методов, которые позволяют извлекать из этих данных полезные знания и принимать более обоснованные решения."],"metadata":{"id":"DT5b4ixP_smd"}},{"cell_type":"markdown","source":["# Проблемы предвзятости и интерпретируемости"],"metadata":{"id":"iyz-ZHdtM8nn"}},{"cell_type":"markdown","source":["**Проблемы предвзятости, прозрачности и интерпретируемости** являются одними из ключевых вызовов в разработке и применении моделей машинного обучения, особенно в тех случаях, когда модели применяются в критически важных областях, таких как здравоохранение, финансы, право или социальные программы. Эти аспекты напрямую влияют на доверие к моделям, их справедливость и их способность объяснять свои решения пользователям.\n","\n","**Предвзятость** в моделях машинного обучения возникает, когда алгоритмы принимают решения, которые систематически несправедливы по отношению к определённым группам людей или категориям данных.\n","\n","- Модель может быть обучена на данных, которые уже содержат предвзятость. Например, если данные о приёме на работу содержат информацию, которая отражает историческую дискриминацию по половому признаку, модель может воспроизводить эту дискриминацию при прогнозировании.\n","\n","- Если метрика, используемая для оценки модели, сама по себе предвзята, то модель может быть нацелена на оптимизацию показателей, которые не учитывают важные социальные или этические факторы. Например, если модель для кредитного скоринга фокусируется только на возврате кредита, она может исключить группы с низкими доходами, даже если они могут вернуть кредит.\n","\n","**Интерпретируемость** касается того, насколько хорошо пользователи и разработчики могут понимать, как и почему модель принимает те или иные решения. Эта проблема особенно остро стоит с использованием сложных моделей, таких как глубокие нейронные сети или ансамбли деревьев решений (например, Random Forest), которые, как правило, рассматриваются как \"чёрные ящики\", поскольку их внутренние механизмы принятия решений трудны для понимания.\n","\n","> Когда модель интерпретируема, пользователи с большей вероятностью будут доверять её предсказаниям, поскольку они могут увидеть причинно-следственные связи между данными и результатом. Человек зачастую опасается полагаться на модели машинного обучения при решении определенных критически важных задач, например, при медицинской диагностике, если не понимает, «как это работает».\n","\n","Хороший пример есть на [wiki ИТМО](https://neerc.ifmo.ru/wiki/index.php?title=%D0%98%D0%BD%D1%82%D0%B5%D1%80%D0%BF%D1%80%D0%B5%D1%82%D0%B8%D1%80%D1%83%D0%B5%D0%BC%D1%8B%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8#.D0.9F.D1.80.D0.B0.D0.BA.D1.82.D0.B8.D1.87.D0.B5.D1.81.D0.BA.D0.B0.D1.8F_.D0.BF.D0.BE.D0.BB.D1.8C.D0.B7.D0.B0):\n","> Например: модель решает, когда нужно класть ковидного больного в палату, а когда отправлять лечиться дома. По статистике люди болеющие астмой выживают чаще, чем здоровые, и логично предположить, что их можно отправлять лечится дома, но дело в том, что этих людей врачи лечат более тщательно, поэтому они и выживают чаще. Если бы мы верили модели в слепую, то люди с астмой просто бы умирали. Поэтому нам важно понять, почему модель пришла к тому или иному выводу.\n","\n","Для повышения интерпретируемости и прозрачности применяются различные подходы, такие как использование более интерпретируемых моделей (например, линейных моделей или решающих деревьев), а также методы объяснения сложных моделей, такие как LIME или SHAP. Эти методы позволяют оценивать влияние каждого признака на конкретное предсказание модели, повышая тем самым её объяснимость. Однако эти методы не объясняют, как именно получено предсказание, так как это не rule-based подход.\n","\n"],"metadata":{"id":"4evJdkKZUY1K"}},{"cell_type":"markdown","source":["\n","<figure>\n","<img src='https://pbs.twimg.com/media/GDFOxNRaAAAko5S.jpg:large' alt='' width='600px'>\n","<figcaption>Модель - «черный ящик», LIME и SHAP - пытаюсь интерпретировать</figcaption>\n","</figure>"],"metadata":{"id":"qrOGD3PYbW0G"}},{"cell_type":"markdown","source":["Однако существует компромисс между интерпретируемостью и сложностью модели. Простые модели, такие как линейные регрессии или решающие деревья, легко интерпретируемы, но они могут быть менее точны при решении сложных задач. Сложные модели, такие как глубокие нейронные сети, могут давать высокую точность, но их интерпретация требует дополнительных методов, что увеличивает сложность их применения в реальных условиях."],"metadata":{"id":"SobhatmqZPS0"}},{"cell_type":"markdown","source":["\n","<figure>\n","<img src='https://neerc.ifmo.ru/wiki/images/thumb/b/bf/Int2acc.jpg/600px-Int2acc.jpg' alt='' width='700px'>\n","<figcaption>Примеры моделей по точности и интерпретируемости</figcaption>\n","</figure>"],"metadata":{"id":"NMpX-Tu_Yid5"}}]}